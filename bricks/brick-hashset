// -*- mode: C++; indent-tabs-mode: nil; c-basic-offset: 4 -*-

/*
 * (c) 2010-2019 Petr Ročkai <code@fixp.eu>
 * (c) 2012-2014 Jiří Weiser <xweiser1@fi.muni.cz>
 * (c) 2013-2014 Vladimír Štill <xstill@fi.muni.cz>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#pragma once

#include <brick-hash>
#include <brick-ptr>
#include <brick-shmem>
#include <brick-bitlevel>
#include <brick-assert>
#include <brick-trace>
#include <brick-types>

#include <type_traits>
#include <set>

/*
 * Various fast hash table implementations, including a concurrent-access hash
 * table. See also ...
 */

namespace brq
{
    template< typename T >
    struct hash_adaptor;

    struct hash_set_stats { size_t used = 0, capacity = 0; };
}

namespace brq::impl
{
    template< typename X >
    auto hash( const X &v ) -> decltype( brq::hash( v ) )
    {
        return brq::hash( v );
    }

    template< typename X >
    auto hash( const X &t ) -> decltype( t.hash() )
    {
        return t.hash();
    }

    inline hash64_t highbits( hash64_t orig, int bits )
    {
        // use a different part of the hash than what we use for indexing
        return orig >> ( sizeof( hash64_t ) * 8 - bits );
    }

    /*
     * Tables are represented as vectors of cells.
     */

    template< typename T >
    struct cell_base
    {
        using value_type = T;
        using reference = const T &;
        using pointer = const T *;
        static constexpr bool can_tombstone() { return false; }
        bool tombstone() const { return false; }
    };

    template< typename T >
    struct fast_cell : cell_base< T >
    {
        T _value = T();
        hash64_t _hash = 0; // TODO: re-use when rehashing

        bool match( hash64_t h ) const { return _hash == h; }
        bool invalid() const { return false; }
        bool empty() const { return !_hash; }
        const T *value() const { return &_value; }
        T &fetch() { return _value; }
        T copy() { return _value; }

        void store( const T &t, hash64_t h ) { _hash = h; _value = t; }
        bool try_store( const T &t, hash64_t h ) { store( t, h ); return true; }
        fast_cell invalidate() { return *this; }
    };

    template< typename T >
    struct compact_cell : cell_base< T >
    {
        T _value = T();

        bool match( hash64_t ) const { return true; }
        bool empty() const { return !_value; } /* meh */
        bool invalid() const { return false; }
        const T *value() const { return &_value; }
        T &fetch() { return _value; }
        T copy() { return _value; }

        void store( T bn, hash64_t ) { _value = bn; }
        bool try_store( T v, hash64_t h ) { store( v, h ); return true; }
        compact_cell invalidate() { return *this; }
    };

    template< typename T >
    struct locked_cell : cell_base< T >
    {
        /* 2 least-significant bits are special */
        std::atomic< hash32_t > _hashlock;
        T _value;

        bool empty() const { return _hashlock == 0; }
        bool invalid() const { return _hashlock == 3; }
        bool tombstone() const { return _hashlock == 2; }

        const T *value() const { return &_value; }
        T &fetch() { return _value; }
        T copy() { return _value; }

        // wait for another write; returns false if cell was invalidated
        bool wait() const
        {
            while ( _hashlock & 1 )
                if ( invalid() )
                    return false;
            return !tombstone();
        }

        bool match( hash32_t hash ) const
        {
            hash |= 1;
            if ( ( ( hash << 2 ) | 1 ) != ( _hashlock | 1 ) )
                return false;
            if ( wait() )
                return true;
            else
                return false;
        }

        static constexpr bool can_tombstone() { return true; }

        /* returns old cell value */
        locked_cell invalidate()
        {
            // wait for write to end
            hash32_t prev = 0;
            while ( !_hashlock.compare_exchange_weak( prev, 3 ) )
            {
                if ( prev == 3 ) /* already invalid */
                    return locked_cell( prev, _value );
                if ( prev != 2 )
                    prev &= ~3; // clean flags
            }
            return locked_cell( prev, _value );
        }

        bool bury()
        {
            hash32_t hl = _hashlock.load();
            if ( invalid() )
                return false;
            return _hashlock.compare_exchange_strong( hl, 2 );
        }

        bool try_store( const T &v, hash32_t hash )
        {
            hash |= 1;
            hash32_t chl = 0;
            if ( _hashlock.compare_exchange_strong( chl, (hash << 2) | 1 ) )
            {
                _value = v;
                _hashlock.exchange( hash << 2 ); /* unlock */
                return true;
            }
            return false;
        }

        void store( const T &v, hash32_t hash )
        {
            _hashlock = hash << 2;
            _value = v;
        }

        locked_cell() : _hashlock( 0 ), _value() {}

    private:
        locked_cell( hash32_t h, const T &val ) : _hashlock( h ), _value( val ) {}
    };

    template< typename T, typename = void >
    struct tagged
    {
        using Type = tagged< T >;
        struct Align { T a; uint16_t b; };
        using Tag = brick::bitlevel::bitvec< 8 * ( sizeof( Align ) - sizeof( T ) ) >;
        struct Check { T a; Tag b; };
        static_assert( sizeof( Align ) == sizeof( Check ) );
        static_assert( sizeof( Check ) == sizeof( T ) + sizeof( Tag ) );

        T _value;
        Tag _tag;

        static const int tag_bits = sizeof( Tag ) * 8;

        T &value() { return _value; }
        const T &value() const { return _value; }
        void tag( Tag v ) { _tag = v; }
        Tag tag() { return _tag; }
        tagged() noexcept : _value(), _tag( 0 ) {}
        explicit tagged( const T &v ) : _value( v ), _tag( 0 ) {}
        operator T() const { return _value; }

        friend std::ostream &operator<<( std::ostream &o, const tagged< T > &v )
        {
            return o << "[" << v._value << " " << uint64_t( v._tag ) << "]";
        }

        static T fetch( const std::atomic< Type > &t ) { return t.load().value(); }
        static T fetch( const Type &t ) { return t; }
    };

    template< typename T >
    struct tagged< T, typename std::enable_if< (T::tag_bits > 0) >::type > : T
    {
        using Type = T;
        static T fetch( const std::atomic< T > &t ) { return t.load(); }
        static T fetch( const T &t ) { return t; }
    };

    template< typename T >
    struct alignas( std::min( 16ul, sizeof( tagged< T > ) ) ) atomic_cell : cell_base< T >
    {
        using tagged = impl::tagged< T >;
        using bare_value = typename tagged::Type;
        using atomic_value = std::atomic< bare_value >;
        using pointer = const atomic_value *;
        using reference = const atomic_value &;

        atomic_value _value;

        static_assert( atomic_value::is_always_lock_free );
        static_assert( bare_value::tag_bits >= 2, "T has at least a two-bit tagspace" );

        static constexpr bool can_tombstone() { return true; }

        uint32_t status() const { return _value.load().tag() & 3u; }
        static hash64_t hashbits( hash64_t in ) { return highbits( in, bare_value::tag_bits - 2 ) << 2; }

        bool empty() const { return status() == 0; }
        bool invalid() const { return status() == 1; }
        bool tombstone() const { return status() == 2; }

        pointer value() const { return &_value; }
        T fetch() const { return tagged::fetch( _value ); }
        T copy() const { bare_value v = _value; v.tag( 0 ); return tagged::fetch( v ); }
        bool wait() { return !invalid(); }
        bool match( hash64_t hash ) const { return _value.load().tag() == ( hashbits( hash ) | 3 ); }
        bool tombstone( hash64_t hash ) const { return _value.load().tag() == ( hashbits( hash ) | 2 ); }

        /* returns old cell value */
        atomic_cell invalidate()
        {
            bare_value expect = _value, update = _value;
            update.tag( 1 );
            while ( !_value.compare_exchange_weak( expect, update ) )
            {
                update = expect;
                update.tag( 1 );
            }
            return atomic_cell( expect );
        }

        bool bury()
        {
            bare_value expect = _value, update = expect;
            if ( invalid() )
                return false;
            update.tag( ( update.tag() & ~decltype( update.tag() )( 3 ) ) | 2 );
            return _value.compare_exchange_strong( expect, update );
        }

        bool revive()
        {
            bare_value expect = _value, update = expect;
            if ( invalid() )
                return false;
            update.tag( update.tag() | 3u );
            return _value.compare_exchange_strong( expect, update );
        }

        void store( T bn, hash64_t hash )
        {
            bare_value next( bn );
            next.tag( hashbits( hash ) | 3 );
            _value.store( next );
        }

        bool try_store( T b, hash64_t hash )
        {
            bare_value zero, tomb;
            bare_value next( b );
            next.tag( hashbits( hash ) | 3 );
            tomb.tag( 2 );
            auto rv = _value.compare_exchange_strong( zero, next );
            if ( !rv )
                rv = _value.compare_exchange_strong( tomb, next );
            return rv;
        }

        atomic_cell() : _value() {}
        atomic_cell( const atomic_cell & ) : _value() {}
        explicit atomic_cell( bare_value val ) : _value( val ) {}
    };

    template< typename T >
    using default_cell = std::conditional_t< ( sizeof( T ) < 16 ), compact_cell< T >, fast_cell< T > >;

    template< typename T, typename = void > struct is_lock_free : std::false_type {};
    template< typename T >
    struct is_lock_free< T, std::enable_if_t< std::is_trivially_copy_constructible_v< T > > >
    {
        static constexpr bool value = std::atomic< typename tagged< T >::Type >::is_always_lock_free;
    };

    template< typename T >
    using concurrent_cell =
        std::conditional_t< is_lock_free< T >::value, atomic_cell< T >, locked_cell< T > >;

    template< typename cell_t_ >
    struct hash_set_base
    {
        using cell_t = cell_t_;
        using value_type = typename cell_t::value_type;
        using pointer = typename cell_t::pointer;
        using reference = typename cell_t::reference;

        struct iterator
        {
            pointer _value;
            bool _new;

            iterator( pointer v = nullptr, bool n = false )
                : _value( v ), _new( n )
            {}
            pointer operator->() const { return _value; }
            reference operator*() const { return *_value; }
            value_type copy() const { return **this; }
            bool valid() const { return _value; }
            bool isnew() const { return _new; }
        };

        iterator end() { return iterator(); }
    };

    template< typename cell_t, unsigned max_chain, unsigned Segment, bool concurrent,
              typename static_allocator >
    struct hash_table : brq::refcount_base< uint16_t, true >
    {
        std::atomic< int32_t > to_rehash;
        std::atomic< size_t > _size;

        using self_alloc = typename static_allocator::template rebind< hash_table >;
        using self_ptr = typename self_alloc::pointer;
        using next_ptr = brq::refcount_ptr< hash_table, concurrent, self_alloc >;
        next_ptr next;

        std::byte _data[];
        cell_t &data( int i = 0 ) { return reinterpret_cast< cell_t * >( _data )[ i ]; }

        using value_type = typename cell_t::value_type;

        enum LookupTag { Found, Empty, Invalid };
        using Lookup = std::pair< typename cell_t::pointer, LookupTag >;
        enum InsertMode { Rehash, Insert };

        template< typename stream >
        friend auto operator<<( stream &o, LookupTag t ) -> decltype( o << "" )
        {
            switch ( t )
            {
                case Found: return o << "found";
                case Empty: return o << "empty";
                case Invalid: return o << "invalid";
                default: return o << int( t );
            }
        }

        static self_ptr construct( size_t cellcount, int32_t rehash )
        {
            auto mem = self_alloc::allocate( sizeof( hash_table ) + cellcount * sizeof( cell_t ) );
            new ( &*mem ) hash_table( cellcount, rehash );
            return mem;
        }

        static void operator delete( void *v )
        {
            static_allocator::free( v );
        }

        hash_table( size_t size, int32_t rehash )
            : to_rehash( rehash ), _size( size ), next()
        {
            std::uninitialized_default_construct( &data(), &data() + size );
        }

        ~hash_table()
        {
            auto s = size();
            for ( decltype( s ) i = 0; i < s; ++i )
                data( i ).~cell_t();
        }

        size_t size() { return _size.load( std::memory_order_relaxed ); }
        size_t segment_size() { return Segment; }
        size_t segment_count() { return size() / segment_size(); }
        cell_t *segment_end( int id ) { return segment_begin( id ) + segment_size(); }
        cell_t *segment_begin( int id )
        {
            ASSERT_LT( id, segment_count() );
            return &data() + segment_size() * id;
        }

        static constexpr const size_t cluster_bytes = 32;
        static constexpr const size_t cluster_size = std::max( 1ul, cluster_bytes / sizeof( cell_t ) );

        static size_t index( hash64_t h, unsigned i, size_t mask )
        {
            const unsigned Q = 1, R = 1;
            size_t j = i % cluster_size; /* index within cluster */
            i = i / cluster_size;        /* index to the start of the cluster */
            size_t hop = (2 * Q + 1) * i + 2 * R * i * i;
            return ( h + j + hop * cluster_size ) & mask;
        }

        template< typename X, typename A > [[gnu::always_inline]]
        Lookup insert( const X &x, hash64_t h, const A &adaptor, InsertMode mode = Insert )
        {
            const size_t mask = size() - 1;
            const unsigned max = mode == Rehash ? 3 * max_chain / 4 : max_chain;

            ASSERT_EQ( mask & size(), 0 );
            ASSERT_EQ( mask | size(), mask + size() );

            cell_t *tomb = nullptr;

            for ( unsigned i = 0; i < max; ++i )
            {
                cell_t &cell = data( index( h, i, mask ) );

                if ( cell.invalid() )
                    return { nullptr, Invalid };

                if ( cell.empty() )
                {
                    if constexpr ( !concurrent )
                        if ( tomb && tomb->try_store( x, h ) )
                            return { tomb->value(), Empty };

                    if ( cell.try_store( x, h ) )
                        return { cell.value(), Empty };
                }

                if constexpr ( !concurrent )
                    if ( !tomb && cell.tombstone() )
                        tomb = &cell;

                if ( auto v = adaptor.match( cell, x, h ) )
                    return { v, Found };
            }

            TRACE( "insert failed after", max, "collisions on", x, "hash", std::hex, h );
            return { nullptr, Empty };
        }

        template< typename X, typename F >
        auto find_generic( const X &x, hash64_t h, F match )
        {
            using res_t = std::pair< decltype( match( std::declval< cell_t & >(), x, h ) ), LookupTag >;
            const size_t mask = size() - 1;

            for ( size_t i = 0; i < max_chain; ++i )
            {
                cell_t &cell = data( index( h, i, mask ) );
                if ( cell.invalid() )
                    return res_t{ nullptr, Invalid };
                if ( cell.empty() )
                    return res_t{ nullptr, Empty };
                if ( auto v = match( cell, x, h ) )
                    return res_t{ v, Found };
            }
            return res_t{ nullptr, Empty };
        }

        template< typename X, typename A >
        Lookup find( const X &x, hash64_t h, const A &adaptor )
        {
            auto m = [&]( cell_t &c, const X &x, hash64_t h ) { return adaptor.match( c, x, h ); };
            return find_generic( x, h, m );
        }
    };

    template< size_t I, size_t... Next >
    struct grow
    {
        static constexpr const size_t Initial = I;

        template< size_t >
        static size_t next( size_t s ) { return 2 * s; }

        template< size_t X, size_t Y, size_t... S >
        static size_t next( size_t s )
        {
            if ( s == X )
                return Y;
            else
                return next< Y, S... >( s );
        }

        static size_t next_size( size_t s )
        {
            return next< I, Next... >( s );
        }
    };

    using quick = grow< 0x100, 0x1000, 0x10000, 0x80000, 0x100000, 0x400000 >;
    using slow  = grow< 0x10 >;

    template< typename cell, bool concurrent, typename grow_t = impl::quick, int max_chain = 24,
              typename static_allocator = std_malloc< std::byte > >
    struct hash_set : hash_set_base< cell >
    {
        using Base = hash_set_base< cell >;
        using Self = hash_set< cell, concurrent, grow_t, max_chain >;

        using typename Base::value_type;
        using typename Base::iterator;
        using table = impl::hash_table< cell, max_chain, grow_t::Initial, concurrent, static_allocator >;
        using table_ptr = brq::refcount_ptr< table, false, typename table::self_alloc >;

        table_ptr _table;

        size_t capacity()
        {
            while ( await_update() );
            return _table->size();
        }

        hash_set_stats stats()
        {
            while ( await_update() );

            hash_set_stats st;
            st.capacity = _table->size();
            for ( size_t i = 0; i < st.capacity; ++i )
                if ( !_table->data( i ).empty() )
                    st.used ++;
            return st;
        }

        template< typename A >
        bool check_outdated( const A &adaptor )
        {
            if constexpr ( !concurrent )
                return false;

            auto next = _table->next;
            if ( !next )
                return false;

            while ( rehash_segment( adaptor, *_table, *next ) );

            await_update();
            check_outdated( adaptor );

            return true;
        }

        bool await_update()
        {
            if ( _table->next )
            {
                _table = _table->next;
                while ( _table->to_rehash.load() < 0 );
                return true;
            }
            return false;
        }

        template< typename X, typename A = hash_adaptor< value_type > >
        iterator insert( const X &x, const A &adaptor = A() )
        {
            return insert( x, adaptor.hash( x ), adaptor );
        }

        template< typename X, typename A = hash_adaptor< value_type > >
        iterator insert( const X &x, hash64_t h, const A &adaptor = A(), bool wasnew = false )
        {
            auto [ value, outcome ] = _table->insert( x, h, adaptor, table::Insert );

            if ( !value && outcome == table::Empty )
                return grow( adaptor ), insert( x, h, adaptor );

            if ( check_outdated( adaptor ) )
            {
                TRACE( _table, "insert", x, "→ outdated, retrying; outcome was", outcome );
                return insert( x, h, adaptor, outcome == table::Empty );
            }

            ASSERT_NEQ( outcome, table::Invalid );
            TRACE( _table, "insert", x, "hash", std::hex, h, "→",
                   wasnew || outcome == table::Empty ? "new" : "old" );
            return iterator( value, wasnew || outcome == table::Empty );
        }

        template< typename X, typename A = hash_adaptor< value_type > >
        iterator find( const X &x, const A &adaptor = A() )
        {
            return find( x, adaptor.hash( x ), adaptor );
        }

        template< typename X, typename A = hash_adaptor< value_type > >
        iterator find( const X &x, hash64_t h, const A &adaptor = A() )
        {
            auto [ value, outcome ] = _table->find( x, h, adaptor );
            if ( check_outdated( adaptor ) )
                return find( x, h, adaptor );
            else
                return iterator( value );
        }

        template< typename X, typename A = hash_adaptor< value_type > >
        bool erase( const X &x, const A &adaptor = A() )
        {
            return erase( x, adaptor.hash( x ), adaptor );
        }

        template< typename X, typename A = hash_adaptor< value_type > >
        bool erase( const X &x, hash64_t h, const A &adaptor = A() )
        {
            static_assert( cell::can_tombstone() );

            bool buried = false;
            auto match_erase = [&]( cell &c, const X &x, hash64_t h )
            {
                switch ( adaptor.erase( c, x, h ) )
                {
                    case A::Bury: buried = c.bury(); return true;
                    case A::Done: buried = true; return true;
                    case A::Mismatch: return false;
                }
            };

            auto [ c, outcome ]  = _table->find_generic( x, h, match_erase );

            if ( outcome == table::Found && !buried )
                outcome = table::Invalid;

            if ( check_outdated( adaptor ) )
            {
                TRACE( _table, "erase outdated, retry?", outcome == table::Found ? "no" : "yes" );
                return outcome == table::Found || erase( x, h, adaptor );
            }
            else
            {
                TRACE( _table, "erase", x, "hash", std::hex, h, "outcome", outcome );
                ASSERT_NEQ( outcome, table::Invalid );
                return outcome == table::Found;
            }
        }

        template< typename T, typename A = hash_adaptor< value_type > >
        int count( const T &x, const A &adaptor = A() ) { return find( x, adaptor ).valid() ? 1 : 0; }

        static std::pair< ssize_t, bool > atomic_add_if_nonzero( std::atomic< int32_t > &v, int off )
        {
            int32_t current = v.load(), next = current + off;
            if ( current )
                while ( !v.compare_exchange_weak( current, next ) && current )
                    next = current + off;

            if ( current )
                return { next, true };
            else
                return { 0, false };
        }

        template< typename A >
        bool rehash_segment( const A &adaptor, table &from, table &to )
        {
            auto [ id, success ] = atomic_add_if_nonzero( from.to_rehash, -1 );
            if ( !success )
                return false;

            TRACE( _table, "rehash segment", id, "from", &from, "to", &to );
            for ( auto c = from.segment_begin( id ); c != from.segment_end( id ); ++ c )
            {
                cell insert = c->invalidate();

                if ( insert.empty() || insert.invalid() )
                    continue;

                adaptor.invalidate( insert );

                if ( insert.tombstone() )
                    continue;

                auto value = insert.fetch();
                hash64_t hash = adaptor.hash( value );
                auto [ result, outcome ] = to.insert( value, hash, adaptor, table::Rehash );
                ASSERT_EQ( outcome, table::Empty );

                if ( !result )
                {
                    string_builder err;
                    err << "hash table " << _table << " failed to rehash at size " << _table->size();
                    to.to_rehash.store( 0 ); /* prevent stalls and deadlocks */
                    throw std::runtime_error( err.buffer() );
                }
            }

            TRACE( _table, "rehash", id, "done" );
            ++ to.to_rehash;
            return id > 0;
        }

        auto make_table( size_t size, ssize_t rehash )
        {
            return table_ptr( table::construct( size, rehash ) );
        }

        template< typename A >
        void grow( const A &adaptor )
        {
            auto next = make_table( grow_t::next_size( _table->size() ), -_table->segment_count() - 1 );
            table_ptr expect;

            TRACE( _table, "grow from", _table->size(), "to", grow_t::next_size( _table->size() ) );
            if ( _table->next.compare_exchange_strong( expect, next ) )
            {
                while ( rehash_segment( adaptor, *_table, *next ) );
                ASSERT_EQ( _table->to_rehash.load(), 0 );
                _table = next;
                while ( _table->to_rehash.load() != -1 );
                _table->to_rehash = _table->segment_count();
            }
            else
            {
                next.reset();
                check_outdated( adaptor );
                return;
            }
            TRACE( _table, "growth done" );
        }

        hash_set()
        {
            _table = make_table( grow_t::Initial, 0 );
            _table->to_rehash = _table->segment_count();
        }

        template< typename T >
        hash_set( const std::enable_if_t< std::is_same_v< T, Self > && !concurrent, hash_set > &o )
        {
            _table = make_table( o.capacity(), 0 );
            _table->to_rehash = _table->segment_count();
            /* TODO avoid the default-construct + overwrite here */
            std::copy( &o._table->data(), &o._table->data() + capacity(), &_table->data() );
        }

        cell &cell_at( size_t index ) { return _table->data( index ); }
        value_type valueAt( size_t idx ) { return cell_at( idx ).fetch(); }
        bool valid( size_t idx ) { return !cell_at( idx ).empty(); }
    };

}

namespace brq
{
    template< typename T >
    struct hash_adaptor
    {
        using value_type = T;
        using Payload = std::pair< T, hash64_t >;
        enum Erase { Bury, Done, Mismatch };

        template< typename X >
        hash64_t hash( const X &x ) const
        {
            return impl::hash( value_type( x ) );
        }

        template< typename cell, typename X >
        typename cell::pointer match( cell &c, const X &t, hash64_t h ) const
        {
            return c.match( h ) && c.fetch() == t ? c.value() : nullptr;
        }

        template< typename cell, typename X >
        Erase erase( cell &c, const X &t, hash64_t ) const
        {
            return c.fetch() == t ? Bury : Mismatch;
        }

        template< typename cell >
        void invalidate( const cell & ) const {}
    };

    template< typename type, typename grow = impl::quick, int max_chain = 24,
              typename alloc = std_malloc< type > >
    using hash_set = impl::hash_set< impl::default_cell< type >, false, grow, max_chain, alloc >;

    template< typename type, typename grow = impl::quick, int max_chain = 24,
              typename alloc = std_malloc< type > >
    using concurrent_hash_set = impl::hash_set< impl::concurrent_cell< type >, true, grow,
                                                max_chain, alloc >;
}

// vim: syntax=cpp tabstop=4 shiftwidth=4 expandtab ft=cpp
