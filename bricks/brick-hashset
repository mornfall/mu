// -*- mode: C++; indent-tabs-mode: nil; c-basic-offset: 4 -*-

/*
 * (c) 2010-2019 Petr Ročkai <code@fixp.eu>
 * (c) 2012-2014 Jiří Weiser <xweiser1@fi.muni.cz>
 * (c) 2013-2014 Vladimír Štill <xstill@fi.muni.cz>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#pragma once

#include <brick-hash>
#include <brick-shmem>
#include <brick-bitlevel>
#include <brick-assert>
#include <brick-trace>
#include <brick-types>

#include <type_traits>
#include <set>

/*
 * Various fast hash table implementations, including a concurrent-access hash
 * table. See also ...
 */

namespace brick::hashset
{

    using hash::hash32_t;
    using hash::hash64_t;

    template< typename X >
    auto hash( const X &v ) -> decltype( hash::hash( v ) )
    {
        return hash::hash( v );
    }

    template< typename X >
    auto hash( const X &t ) -> decltype( t.hash() )
    {
        return t.hash();
    }

    template< typename T >
    struct DefaultLookup
    {
        using value_type = T;

        value_type value;
        hash64_t hash;

        explicit DefaultLookup( const value_type &v ) { reset( v ); }

        void reset( const value_type &v )
        {
            value = v;
            hash = hashset::hash( v );
        }

        template< typename X >
        auto equal( const X &t ) const -> decltype( value == t )
        {
            return value == t;
        }
    };

    static inline hash64_t highbits( hash64_t orig, int bits )
    {
        // use a different part of the hash than what we use for indexing
        return orig >> ( sizeof( hash64_t ) * 8 - bits );
    }

    /*
     * Tables are represented as vectors of cells.
     */

    template< typename T >
    struct CellBase
    {
        using value_type = T;
        static constexpr bool can_tombstone() { return false; }
        bool tombstone() { return false; }
    };

    template< typename T >
    struct FastCell : CellBase< T >
    {
        T _value;
        hash64_t _hash; // TODO: re-use when rehashing

        template< typename Lookup >
        bool equal( const Lookup &x )
        {
            return _hash == x.hash && x.equal( _value );
        }

        void store( const T &t, hash64_t h )
        {
            _hash = h;
            _value = t;
        }

        bool try_store( const T &t, hash64_t h )
        {
            store( t, h );
            return true;
        }

        bool invalid() { return false; }
        bool empty() { return !_hash; }
        FastCell invalidate() { return *this; }

        T &fetch() { return _value; }
        T copy() { return _value; }
    };

    template< typename T >
    struct CompactCell : CellBase< T >
    {
        T _value;

        template< typename Lookup >
        bool equal( const Lookup &x )
        {
            return x.equal( _value );
        }

        bool empty() { return !_value; } /* meh */
        void store( T bn, hash64_t ) { _value = bn; }
        bool try_store( T v, hash64_t h ) { store( v, h ); return true; }
        bool invalid() { return false; }
        CompactCell invalidate() { return *this; }

        T &fetch() { return _value; }
        T copy() { return _value; }
    };

    template< typename T >
    struct LockedCell : CellBase< T >
    {
        /* 2 least-significant bits are special */
        std::atomic< hash32_t > _hashlock;
        T _value;

        bool empty() { return _hashlock == 0; }
        bool invalid() { return _hashlock == 3; }
        bool tombstone() { return _hashlock == 2; }

        static constexpr bool can_tombstone() { return true; }

        /* returns old cell value */
        LockedCell invalidate()
        {
            // wait for write to end
            hash32_t prev = 0;
            while ( !_hashlock.compare_exchange_weak( prev, 3 ) )
            {
                if ( prev == 3 ) /* already invalid */
                    return LockedCell( prev, _value );
                if ( prev != 2 )
                    prev &= ~3; // clean flags
            }
            return LockedCell( prev, _value );
        }

        bool bury()
        {
            hash32_t hl = _hashlock.load();
            if ( invalid() )
                return false;
            return _hashlock.compare_exchange_strong( hl, 2 );
        }

        T &fetch() { return _value; }
        T copy() { return _value; }

        // wait for another write; returns false if cell was invalidated
        bool wait()
        {
            while ( _hashlock & 1 )
                if ( invalid() )
                    return false;
            return !tombstone();
        }

        bool try_store( const T &v, hash32_t hash )
        {
            hash |= 1;
            hash32_t chl = 0;
            if ( _hashlock.compare_exchange_strong( chl, (hash << 2) | 1 ) )
            {
                _value = v;
                _hashlock.exchange( hash << 2 ); /* unlock */
                return true;
            }
            return false;
        }

        void store( const T &v, hash32_t hash )
        {
            _hashlock = hash << 2;
            _value = v;
        }

        template< typename Lookup >
        auto equal( const Lookup &x ) -> decltype( x.equal( _value ), true )
        {
            hash32_t hash = x.hash | 1;
            if ( ( ( hash << 2 ) | 1 ) != ( _hashlock | 1 ) )
                return false;
            if ( !wait() )
                return false;
            return x.equal( _value );
        }

        LockedCell() : _hashlock( 0 ), _value() {}

    private:
        LockedCell( hash32_t h, const T &val ) : _hashlock( h ), _value( val ) {}
    };

    template< typename T, typename = void >
    struct Tagged
    {
        struct Align { T a; uint16_t b; };
        using Tag = bitlevel::bitvec< 8 * ( sizeof( Align ) - sizeof( T ) ) >;
        struct Check { T a; Tag b; };
        static_assert( sizeof( Align ) == sizeof( Check ) );
        static_assert( sizeof( Check ) == sizeof( T ) + sizeof( Tag ) );

        T _value;
        Tag _tag;

        static const int tag_bits = sizeof( Tag ) * 8;

        T &value() { return _value; }
        void tag( Tag v ) { _tag = v; }
        Tag tag() { return _tag; }
        Tagged() noexcept : _value(), _tag( 0 ) {}
        explicit Tagged( const T &v ) : _value( v ), _tag( 0 ) {}

        friend std::ostream &operator<<( std::ostream &o, const Tagged< T > &v )
        {
            return o << "[" << v._value << " " << uint64_t( v._tag ) << "]";
        }
    };

    template< typename T >
    struct Tagged< T, typename std::enable_if< (T::tag_bits > 0) >::type >
    {
        T _value;

        static const int tag_bits = T::tag_bits;
        T &value() { return _value; }
        void tag( uint32_t value ) { _value.tag( value ); }
        uint32_t tag() { return _value.tag(); }
        Tagged() noexcept : _value() {}
        explicit Tagged( const T &v ) : _value( v ) {}
    };

    template< typename T >
    struct alignas( std::min( 16ul, sizeof( Tagged< T > ) ) ) AtomicCell : CellBase< T >
    {
        std::atomic< Tagged< T > > value;

        static_assert( sizeof( std::atomic< Tagged< T > > ) == sizeof( Tagged< T > ),
                       "std::atomic< Tagged< T > > must be lock-free" );
        static_assert( Tagged< T >::tag_bits >= 2, "T has at least a two-bit tagspace" );

        static constexpr bool can_tombstone() { return true; }

        uint32_t status() { return value.load().tag() & 3u; }

        bool empty() { return status() == 0; }
        bool invalid() { return status() == 1; }
        bool tombstone() { return status() == 2; }

        /* returns old cell value */
        AtomicCell invalidate()
        {
            Tagged< T > expect = value, update = value;
            update.tag( 1 );
            while ( !value.compare_exchange_weak( expect, update ) )
            {
                update = expect;
                update.tag( 1 );
            }
            return AtomicCell( expect );
        }

        bool bury()
        {
            Tagged< T > expect = value, update;
            if ( invalid() )
                return false;
            update.tag( 2 );
            return value.compare_exchange_strong( expect, update );
        }

        static hash64_t hashbits( hash64_t in ) { return highbits( in, Tagged< T >::tag_bits - 2 ) << 2; }

        T fetch() { return value.load().value(); }
        T copy() { Tagged< T > v = value; v.tag( 0 ); return v.value(); }
        bool wait() { return !invalid(); }

        void store( T bn, hash64_t hash )
        {
            Tagged< T > next( bn );
            next.tag( hashbits( hash ) | 3 );
            value.store( next );
        }

        bool try_store( T b, hash64_t hash )
        {
            Tagged< T > zero, tomb;
            Tagged< T > next( b );
            next.tag( hashbits( hash ) | 3 );
            tomb.tag( 2 );
            auto rv = value.compare_exchange_strong( zero, next );
            if ( !rv )
                rv = value.compare_exchange_strong( tomb, next );
            return rv;
        }

        template< typename Lookup >
        bool equal( const Lookup &x )
        {
            return value.load().tag() == ( hashbits( x.hash ) | 3 ) &&
                   x.equal( value.load().value() );
        }

        AtomicCell() : value() {}
        AtomicCell( const AtomicCell & ) : value() {}
        explicit AtomicCell( Tagged< T > val ) : value( val ) {}
    };

    template< typename Cell_ >
    struct HashSetBase
    {
        using Cell = Cell_;
        using value_type = typename Cell::value_type;

        struct proxy
        {
            value_type v;
            value_type *operator->() { return &v; }
        };

        struct iterator
        {
            Cell *_cell;
            value_type _value;
            bool _new;

            iterator( Cell *c = nullptr, bool n = false )
                : _cell( c ), _value( c ? c->fetch() : value_type() ), _new( n )
            {}
            proxy operator->() { return proxy( _value ); }
            value_type operator*() { return _value; }
            value_type copy() { return _cell->copy(); }
            void update( value_type v ) { _cell->store( v ); }
            bool valid() { return _cell; }
            bool isnew() { return _new; }
        };

        iterator end() { return iterator(); }
    };

    template< typename Cell, unsigned MaxChain, unsigned Segment >
    struct Table
    {
        std::shared_ptr< Table > next; /* TODO make std::atomic after C++20 */
        std::atomic< size_t > _size;
        std::atomic< ssize_t > to_rehash;
        Cell data[];

        using value_type = typename Cell::value_type;

        enum LookupTag { Found, Empty, Invalid };
        using Lookup = std::pair< Cell *, LookupTag >;
        enum InsertMode { Rehash, Replace, Insert };

        static void *operator new( size_t objsize, size_t cellcount )
        {
            auto rv = malloc( objsize + cellcount * sizeof( Cell ) );
            if ( !rv )
                throw std::bad_alloc();
            return rv;
        }

        Table( size_t size, ssize_t rehash )
            : next( nullptr ), _size( size ), to_rehash( rehash )
        {
            std::uninitialized_default_construct( data, data + size );
        }

        size_t size() { return _size.load( std::memory_order_relaxed ); }
        size_t segment_size() { return Segment; }
        size_t segment_count() { return size() / segment_size(); }
        Cell *segment_end( int id ) { return segment_begin( id ) + segment_size(); }
        Cell *segment_begin( int id )
        {
            ASSERT_LT( id, segment_count() );
            return data + segment_size() * id;
        }

        static constexpr const size_t cluster_bytes = 32;
        static constexpr const size_t cluster_size = std::max( 1ul, cluster_bytes / sizeof( Cell ) );

        static size_t index( hash64_t h, unsigned i, size_t mask )
        {
            const unsigned Q = 1, R = 1;
            size_t j = i % cluster_size; /* index within cluster */
            i = i / cluster_size;        /* index to the start of the cluster */
            size_t hop = (2 * Q + 1) * i + 2 * R * i * i;
            return ( h + j + hop * cluster_size ) & mask;
        }

        template< typename X > [[gnu::always_inline]]
        Lookup insert( const X &x, InsertMode mode = Insert )
        {
            const size_t mask = size() - 1;
            const unsigned max = mode == Rehash ? 3 * MaxChain / 4 : MaxChain;

            ASSERT_EQ( mask & size(), 0 );
            ASSERT_EQ( mask | size(), mask + size() );

            Cell *tomb = nullptr;

            for ( unsigned i = 0; i < max; ++i )
            {
                Cell &cell = data[ index( x.hash, i, mask ) ];

                if ( cell.invalid() )
                    return { &cell, Invalid };

                if ( cell.empty() )
                {
                    if ( tomb && tomb->try_store( x.value, x.hash ) )
                        return { tomb, Empty };

                    if ( cell.try_store( x.value, x.hash ) )
                        return { &cell, Empty };
                }

                if ( !tomb && cell.tombstone() )
                    tomb = &cell;

                if ( cell.equal( x ) )
                {
                    if ( mode == Replace )
                        cell.store( x.value, x.hash );
                    return { &cell, Found };
                }
            }

            TRACE( "insert failed after", max, "collisions on", x.value, "hash", std::hex, x.hash );
            return { nullptr, Empty };
        }

        template< typename X >
        Lookup find( const X &x )
        {
            const size_t mask = size() - 1;

            for ( size_t i = 0; i < MaxChain; ++i )
            {
                Cell &cell = data[ index( x.hash, i, mask ) ];
                if ( cell.invalid() )
                    return { nullptr, Invalid };
                if ( cell.empty() )
                    return { nullptr, Empty };
                if ( cell.equal( x ) )
                    return { &cell, Found };
            }
            return { nullptr, Empty };
        }
    };

    template< size_t I, size_t... Next >
    struct Grow
    {
        static constexpr const size_t Initial = I;

        template< size_t >
        static size_t next( size_t s ) { return 2 * s; }

        template< size_t X, size_t Y, size_t... S >
        static size_t next( size_t s )
        {
            if ( s == X )
                return Y;
            else
                return next< Y, S... >( s );
        }

        static size_t next_size( size_t s )
        {
            return next< I, Next... >( s );
        }
    };

    using Quick = Grow< 0x100, 0x1000, 0x10000, 0x80000, 0x100000, 0x400000 >;
    using Slow  = Grow< 0x10 >;

    template< typename Cell, typename Lookup, bool Concurrent, typename Grow = Quick, int MaxChain = 24 >
    struct HashSet : HashSetBase< Cell >
    {
        using Base = HashSetBase< Cell >;
        using Self = HashSet< Cell, Lookup, Concurrent, Grow, MaxChain >;

        using typename Base::value_type;
        using typename Base::iterator;
        using Table = hashset::Table< Cell, MaxChain, Grow::Initial >;

        std::shared_ptr< Table > _table;

        size_t capacity()
        {
            while ( await_update() );
            return _table->size();
        }

        bool check_outdated( Lookup lookup )
        {
            if constexpr ( !Concurrent )
                return false;

            auto next = std::atomic_load( &_table->next );
            if ( !next )
                return false;

            while ( rehash_segment( lookup, *_table, *next ) );

            await_update();
            check_outdated( lookup );

            return true;
        }

        bool await_update()
        {
            if ( auto next = std::atomic_load( &_table->next ) )
            {
                _table = next;
                while ( _table->to_rehash.load() < 0 );
                return true;
            }
            return false;
        }

        iterator insert( const value_type &x, bool replace = false )
        {
            return insert( Lookup( x ), replace );
        }

        iterator insert( const Lookup &x, bool replace = false, bool wasnew = false )
        {
            auto mode = replace ? Table::Replace : Table::Insert;
            auto [ cell, outcome ] = _table->insert( x, mode );

            if ( !cell )
                return grow( x ), insert( x, replace );

            if ( check_outdated( x ) )
            {
                TRACE( _table, "insert outdated, retrying; outcome was", outcome );
                return insert( x, replace, outcome == Table::Empty );
            }

            ASSERT_NEQ( outcome, Table::Invalid );
            TRACE( _table, "insert", x.value, "hash", std::hex, x.hash, "→",
                   wasnew || outcome == Table::Empty ? "new" : "old" );
            return iterator( cell, wasnew || outcome == Table::Empty );
        }

        iterator find( const value_type &x )
        {
            return find( Lookup( x ) );
        }

        iterator find( const Lookup &x )
        {
            auto [ cell, outcome ] = _table->find( x );
            if ( check_outdated( x ) )
                return find( x );
            else
                return iterator( cell );
        }

        bool erase( const value_type &x )
        {
            return erase( Lookup( x ) );
        }

        bool erase( const Lookup &x )
        {
            static_assert( Cell::can_tombstone() );

            auto [ cell, outcome ]  = _table->find( x );
            if ( outcome == Table::Found )
                outcome = cell->bury() ? Table::Found : Table::Invalid;

            if ( check_outdated( x ) )
            {
                TRACE( _table, "erase outdated, retry?", outcome == Table::Found ? "no" : "yes" );
                return outcome == Table::Found || erase( x );
            }
            else
            {
                TRACE( _table, "erase", x.value, "outcome", outcome );
                ASSERT_NEQ( outcome, Table::Invalid );
                return outcome == Table::Found;
            }
        }

        template< typename T >
        int count( const T &x ) { return find( x ).valid() ? 1 : 0; }

        static std::pair< ssize_t, bool > atomic_add_if_nonzero( std::atomic< ssize_t > &v, int off )
        {
            ssize_t current = v.load(), next = current + off;
            while ( current && !v.compare_exchange_weak( current, next ) )
                next = current + off;
            if ( current )
                return { next, true };
            else
                return { 0, false };
        }

        bool rehash_segment( Lookup &lookup, Table &from, Table &to )
        {
            auto [ id, success ] = atomic_add_if_nonzero( from.to_rehash, -1 );
            if ( !success )
                return false;

            TRACE( _table, "rehash segment", id );
            for ( auto c = from.segment_begin( id ); c != from.segment_end( id ); ++ c )
            {
                Cell insert = c->invalidate();
                if ( insert.empty() || insert.invalid() || insert.tombstone() )
                    continue;

                lookup.reset( insert.fetch() );
                auto [ cell, outcome ] = to.insert( lookup, Table::Rehash );
                ASSERT_EQ( outcome, Table::Empty );

                if ( !cell )
                {
                    std::stringstream err;
                    err << "hash table " << _table << " failed to rehash at size " << _table->size();
                    to.to_rehash.store( 0 ); /* prevent stalls and deadlocks */
                    throw std::runtime_error( err.str() );
                }
            }

            TRACE( _table, "rehash", id, "done" );
            ++ to.to_rehash;
            return id > 0;
        }

        auto make_table( size_t size, ssize_t rehash )
        {
            return std::shared_ptr< Table >( new ( size ) Table( size, rehash ) );
        }

        void grow( const Lookup &skel )
        {
            auto next = make_table( Grow::next_size( _table->size() ), -_table->segment_count() );
            decltype( next ) old;

            TRACE( _table, "grow from", _table->size(), "to", Grow::next_size( _table->size() ) );
            if ( !std::atomic_compare_exchange_strong( &_table->next, &old, next ) )
            {
                next.reset();
                check_outdated( skel );
                return;
            }
            else
            {
                Lookup lookup( skel );
                while ( rehash_segment( lookup, *_table, *next ) );
                ASSERT_EQ( _table->to_rehash.load(), 0 );
                _table = next;
                while ( _table->to_rehash.load() );
                _table->to_rehash = _table->segment_count();
            }
            TRACE( _table, "growth done" );
        }

        HashSet()
        {
            _table = make_table( Grow::Initial, 0 );
            _table->to_rehash = _table->segment_count();
        }

        template< typename T >
        HashSet( const std::enable_if_t< std::is_same_v< T, Self > && !Concurrent, HashSet > &o )
        {
            _table = make_table( o.capacity(), 0 );
            _table->to_rehash = _table->segment_count();
            /* TODO avoid the default-construct + overwrite here */
            std::copy( o._table->data, o._table->data + capacity(), _table->data );
        }

        Cell &cellAt( size_t index ) { return _table->data[ index ]; }
        value_type valueAt( size_t idx ) { return cellAt( idx ).fetch(); }
        bool valid( size_t idx ) { return !cellAt( idx ).empty(); }
    };

    template< typename T, typename Lookup = DefaultLookup< T > >
    using Fast = HashSet< FastCell< T >, Lookup, false >;

    template< typename T, typename Lookup = DefaultLookup< T > >
    using Compact = HashSet< CompactCell< T >, Lookup, false >;

    template< typename T >
    using ConcurrentCell = std::conditional_t< std::atomic< Tagged< T > >::is_always_lock_free,
                                               AtomicCell< T >, LockedCell< T > >;

    template< typename T, typename Lookup = DefaultLookup< T > >
    using Concurrent = HashSet< ConcurrentCell< T >, Lookup, true >;

}

namespace brick::t_hashset {

using namespace hashset;

#ifdef __divine__
static constexpr int size = 4;
#else
static constexpr int size = 32 * 1024;
#endif

struct Big
{
    int v;
    std::array< int, 16 > padding;
    Big( int v = 0 ) : v( v ) {}
    hash64_t hash() const { return hash::hash( v ); }
    bool operator==( const Big &o ) const { return v == o.v; }
    bool operator!() const { return !v; }
    explicit operator bool() const { return v; }
    operator int() const { return v; }
};

template< template< typename > class HS, typename V = int >
struct Sequential
{
    TEST(basic) {
        HS< V > set;

        ASSERT( !set.count( 1 ) );
        ASSERT( set.insert( 1 ).isnew() );
        ASSERT( set.count( 1 ) );

        unsigned count = 0;
        for ( unsigned i = 0; i != set.capacity(); ++i )
            if ( set.valueAt( i ) )
                ++count;

        ASSERT_EQ( count, 1u );
    }

    TEST(stress) {
        HS< V > set;

        for ( int i = 1; i < size; ++i ) {
            set.insert( i );
            ASSERT( set.count( i ) );
        }
        for ( int i = 1; i < size; ++i ) {
            ASSERT( set.count( i ) );
        }
    }

    TEST(erase_basic)
    {
        if constexpr ( HS< V >::Cell::can_tombstone() )
        {
            HS< V > set;

            ASSERT( !set.count( 1 ) );
            ASSERT( set.insert( 1 ).isnew() );
            ASSERT( set.count( 1 ) );
            ASSERT( set.erase( 1 ) );
            ASSERT( !set.count( 1 ) );
            ASSERT( set.insert( 1 ).isnew() );
            ASSERT( set.count( 1 ) );
        }
    }

    TEST(erase_many)
    {
        if constexpr ( HS< V >::Cell::can_tombstone() )
        {
            HS< V > set;

            for ( int i = 1; i < size; ++i )
            {
                set.insert( i );
                ASSERT( set.count( i ) );
                if ( i % 2 == 0 )
                {
                    set.erase( i );
                    ASSERT( !set.count( i ) );
                }
            }

            for ( int i = 1; i < size; ++i )
                ASSERT_EQ( set.count( i ), i % 2 );
        }
    }

    TEST(set) {
        HS< V > set;

        for ( int i = 1; i < size; ++i ) {
            ASSERT( !set.count( i ) );
        }

        for ( int i = 1; i < size; ++i ) {
            set.insert( i );
            ASSERT( set.count( i ) );
            ASSERT( !set.count( i + 1 ) );
        }

        for ( int i = 1; i < size; ++i ) {
            ASSERT( set.count( i ) );
        }

        for ( int i = size; i < 2 * size; ++i ) {
            ASSERT( !set.count( i ) );
        }
    }
};

template< template< typename > class HS, typename V = int >
struct Parallel
{
    struct Insert
    {
        HS< V > set;
        int from, to;
        bool overlap;

        void main() {
            for ( int i = from; i < to; ++i ) {
                set.insert( i );
                ASSERT( !set.insert( i ).isnew() );
                if ( !overlap && i < to - 1 )
                    ASSERT( !set.count( i + 1 ) );
            }
        }
    };

    TEST(insert) {
        Insert a;
        a.from = 1;
        a.to = size;
        a.overlap = false;
        a.main();
        for ( int i = 1; i < size; ++i )
            ASSERT( a.set.count( i ) );
    }

    static HS< V > _par( int f1, int t1, int f2, int t2 )
    {
        shmem::Thread< Insert > a, b( a );

        a.from = f1;
        a.to = t1;
        b.from = f2;
        b.to = t2;
        a.overlap = b.overlap = (t1 > f2);

        a.start();
        b.start();
        a.join();
        b.join();
        return a.set;
    }

    static HS< V > _multi( std::size_t count, int from, int to )
    {
        shmem::ThreadSet< Insert > arr;
        arr.resize( count );

        for ( std::size_t i = 0; i < count; ++i )
        {
            arr[ i ].from = from;
            arr[ i ].to = to;
            arr[ i ].overlap = true;
        }

        arr.start();
        arr.join();

        return arr[ 0 ].set;
    }

    TEST(multi)
    {
        auto set = _multi( 10, 1, size );

        for  ( int i = 1; i < size; ++i )
            ASSERT( set.count( i ) );

        int count = 0;
        std::set< int > s;
        for ( size_t i = 0; i != set.capacity(); ++i ) {
            if ( set.valueAt( i ) ) {
                if ( s.find( set.valueAt( i ) ) == s.end() )
                    s.insert( set.valueAt( i ) );
                ++count;
            }
        }
        ASSERT_EQ( count, size - 1 );
    }

    TEST(stress)
    {
        auto s = _par( 1, size / 2, size / 4, size );

        for ( int i = 1; i < size; ++i )
            ASSERT( s.count( i ) );
    }

    TEST(empty)
    {
        HS< V > set;

        for ( int i = 1; i < size; ++i )
            ASSERT( !set.count( i ) );
    }

    TEST(set)
    {
        auto set = _par( 1, size / 2, size / 2, size );

        for ( int i = 1; i < size; ++i )
            ASSERT_EQ( i, i * set.count( i ) );

        for ( int i = size; i < size * 2; ++i )
            ASSERT( !set.count( i ) );
    }
};

template< typename T > using CS = Compact< T >;
template< typename T > using FS = Fast< T >;
template< typename T > using PS = Concurrent< T >;

/* instantiate the testcases */
template struct Sequential< CS >;
template struct Sequential< FS >;
template struct Sequential< PS >;
template struct Parallel< PS >;

template struct Sequential< CS, int64_t >;
template struct Sequential< FS, int64_t >;
template struct Sequential< PS, int64_t >;
template struct Parallel< PS, int64_t >;

template struct Sequential< CS, Big >;
template struct Sequential< FS, Big >;
template struct Sequential< PS, Big >;
template struct Parallel< PS, Big >;

}

#ifdef BRICK_BENCHMARK_REG

#include <brick-hlist.h>
#include <brick-benchmark.h>
#include <unordered_set>

#ifdef BRICKS_HAVE_TBB
#include <tbb/concurrent_hash_map.h>
#include <tbb/concurrent_unordered_set.h>
#endif

namespace brick {
namespace b_hashset {

template< typename HS >
struct RandomThread : shmem::Thread {
    HS *_set;
    typename HS::ThreadData td;
    int count, id;
    std::mt19937 rand;
    std::uniform_int_distribution<> dist;
    bool insert;
    int max;

    RandomThread() : insert( true ) {}

    void main() {
        rand.seed( id );
        auto set = _set->withTD( td );
        for ( int i = 0; i < count; ++i ) {
            int v = dist( rand );
            if ( max < std::numeric_limits< int >::max() ) {
                v = v % max;
                v = v * v + v + 41; /* spread out the values */
            }
            if ( insert )
                set.insert( v );
            else
                set.count( v );
        }
    };
};

namespace {

Axis axis_items( int min = 16, int max = 16 * 1024 ) {
    Axis a;
    a.type = Axis::Quantitative;
    a.name = "items";
    a.log = true;
    a.step = sqrt(sqrt(2));
    a.normalize = Axis::Div;
    a.unit = "k";
    a.unit_div =    1000;
    a.min = min * 1000;
    a.max = max * 1000;
    return a;
}

Axis axis_threads( int max = 16 ) {
    Axis a;
    a.type = Axis::Quantitative;
    a.name = "threads";
    a.normalize = Axis::Mult;
    a.unit = "";
    a.min = 1;
    a.max = max;
    a.step = 1;
    return a;
}

Axis axis_reserve( int max = 200, int step = 50 )
{
    Axis a;
    a.type = Axis::Quantitative;
    a.name = "reserve";
    a.unit = "%";
    a.min = 0;
    a.max = max;
    a.step = step;
    return a;
}

Axis axis_types( int count )
{
    Axis a;
    a.type = Axis::Qualitative;
    a.name = "type";
    a.unit = "";
    a.min = 0;
    a.max = count - 1;
    a.step = 1;
    return a;
}

}

template< typename T > struct TN {};
template< typename > struct _void { typedef void T; };

template< typename Ts >
struct Run : BenchmarkGroup
{
    template< typename, int Id >
    std::string render( int, hlist::not_preferred ) { return ""; }

    template< typename Tss = Ts, int Id = 0, typename = typename Tss::Head >
    std::string render( int id, hlist::preferred = hlist::preferred() )
    {
        if ( id == Id )
            return TN< typename Tss::Head >::n();
        return render< typename Tss::Tail, Id + 1 >( id, hlist::preferred() );
    }

    std::string describe() {
        std::string s;
        for ( int i = 0; i < int( Ts::length ); ++i )
            s += " type:" + render( i );
        return std::string( s, 1, s.size() );
    }

    template< template< typename > class, typename Self, int, typename, typename... Args >
    static void run( Self *, hlist::not_preferred, Args... ) {
        UNREACHABLE( "brick::b_hashset::Run fell off the cliff" );
    }

    template< template< typename > class RI, typename Self, int id,
              typename Tss, typename... Args >
    static auto run( Self *self, hlist::preferred, Args... args )
        -> typename _void< typename Tss::Head >::T
    {
        if ( self->type() == id ) {
            RI< typename Tss::Head > x( self, args... );
            self->reset(); // do not count the constructor
            x( self );
        } else
            run< RI, Self, id + 1, typename Tss::Tail, Args... >( self, hlist::preferred(), args... );
    }

    template< template< typename > class RI, typename Self, typename... Args >
    static void run( Self *self, Args... args ) {
        run< RI, Self, 0, Ts, Args... >( self, hlist::preferred(), args... );
    }

    int type() { return 0; } // default
};

template< int _threads, typename T >
struct ItemsVsReserve : Run< hlist::TypeList< T > >
{
    ItemsVsReserve() {
        this->x = axis_items();
        this->y = axis_reserve();
    }

    std::string fixed() {
        std::stringstream s;
        s << "threads:" << _threads;
        return s.str();
    }

    int threads() { return _threads; }
    int items() { return this->p; }
    double reserve() { return this->q / 100; }
    double normal() { return _threads; }
};

template< int _max_threads, int _reserve, typename T >
struct ItemsVsThreads : Run< hlist::TypeList< T > >
{
    ItemsVsThreads() {
        this->x = axis_items();
        this->y = axis_threads( _max_threads );
    }

    std::string fixed() {
        std::stringstream s;
        s << "reserve:" << _reserve;
        return s.str();
    }

    int threads() { return this->q; }
    int items() { return this->p; }
    double reserve() { return _reserve / 100.0; }
};

template< int _items, typename T >
struct ThreadsVsReserve : Run< hlist::TypeList< T > >
{
    ThreadsVsReserve() {
        this->x = axis_threads();
        this->y = axis_reserve();
    }

    std::string fixed() {
        std::stringstream s;
        s << "items:" << _items << "k";
        return s.str();
    }

    int threads() { return this->p; }
    int reserve() { return this->q; }
    int items() { return _items * 1000; }
};

template< int _threads, int _reserve, typename... Ts >
struct ItemsVsTypes : Run< hlist::TypeList< Ts... > >
{
    ItemsVsTypes() {
        this->x = axis_items();
        this->y = axis_types( sizeof...( Ts ) );
        this->y._render = [this]( int i ) {
            return this->render( i );
        };
    }

    std::string fixed() {
        std::stringstream s;
        s << "threads:" << _threads << " reserve:" << _reserve;
        return s.str();
    }

    int threads() { return _threads; }
    double reserve() { return _reserve / 100.0; }
    int items() { return this->p; }
    int type() { return this->q; }
    double normal() { return _threads; }
};

template< int _items, int _reserve, int _threads, typename... Ts >
struct ThreadsVsTypes : Run< hlist::TypeList< Ts... > >
{
    ThreadsVsTypes() {
        this->x = axis_threads( _threads );
        this->y = axis_types( sizeof...( Ts ) );
        this->y._render = [this]( int i ) {
            return this->render( i );
        };
    }

    std::string fixed() {
        std::stringstream s;
        s << "items:" << _items << "k reserve:" << _reserve;
        return s.str();
    }

    int threads() { return this->p; }
    double reserve() { return _reserve / 100.0; }
    int items() { return _items * 1000; }
    int type() { return this->q; }
    double normal() { return 1.0 / items(); }
};

template< typename T >
struct RandomInsert {
    bool insert;
    int max;
    using HS = typename T::template HashTable< int >;
    HS t;

    template< typename BG >
    RandomInsert( BG *bg, int max = std::numeric_limits< int >::max() )
        : insert( true ), max( max )
    {
        if ( bg->reserve() > 0 )
            t.reserve( bg->items() * bg->reserve() );
    }

    template< typename BG >
    void operator()( BG *bg )
    {
        RandomThread< HS > *ri = new RandomThread< HS >[ bg->threads() ];

        for ( int i = 0; i < bg->threads(); ++i ) {
            ri[i].id = i;
            ri[i].insert = insert;
            ri[i].max = max;
            ri[i].count = bg->items() / bg->threads();
            ri[i]._set = &t;
        }

        for ( int i = 0; i < bg->threads(); ++i )
            ri[i].start();
        for ( int i = 0; i < bg->threads(); ++i )
            ri[i].join();
    }
};

template< typename T >
struct RandomLookup : RandomInsert< T > {

    template< typename BG >
    RandomLookup( BG *bg, int ins_max, int look_max )
        : RandomInsert< T >( bg, ins_max )
    {
        (*this)( bg );
        this->max = look_max;
        this->insert = false;
    }
};

template< typename Param >
struct Bench : Param
{
    std::string describe() {
        return "category:hashset " + Param::describe() + " " +
            Param::fixed() + " " + this->describe_axes();
    }

    BENCHMARK(random_insert_1x) {
        this->template run< RandomInsert >( this );
    }

    BENCHMARK(random_insert_2x) {
        this->template run< RandomInsert >( this, this->items() / 2 );
    }

    BENCHMARK(random_insert_4x) {
        this->template run< RandomInsert >( this, this->items() / 4 );
    }

    BENCHMARK(random_lookup_100) {
        this->template run< RandomInsert >( this );
    }

    BENCHMARK(random_lookup_50) {
        this->template run< RandomLookup >(
            this, this->items() / 2, this->items() );
    }

    BENCHMARK(random_lookup_25) {
        this->template run< RandomLookup >(
            this, this->items() / 4, this->items() );
    }
};

template< template< typename > class C >
struct wrap_hashset {
    template< typename T > using HashTable = C< T >;
};

template< template< typename > class C >
struct wrap_set {
    template< typename T >
    struct HashTable {
        C< T > *t;
        struct ThreadData {};
        HashTable< T > withTD( ThreadData & ) { return *this; }
        void reserve( int s ) { t->rehash( s ); }
        void insert( T i ) { t->insert( i ); }
        int count( T i ) { return t->count( i ); }
        HashTable() : t( new C< T > ) {}
    };
};

struct empty {};

template< template< typename > class C >
struct wrap_map {
    template< typename T >
    struct HashTable : wrap_set< C >::template HashTable< T >
    {
        template< typename TD >
        HashTable< T > &withTD( TD & ) { return *this; }
        void insert( int v ) {
            this->t->insert( std::make_pair( v, empty() ) );
        }
    };
};

template< typename T >
using unordered_set = std::unordered_set< T >;

using A = wrap_set< unordered_set >;
using B = wrap_hashset< CS >;
using C = wrap_hashset< FS >;
using D = wrap_hashset< PS >;

template<> struct TN< A > { static const char *n() { return "std"; } };
template<> struct TN< B > { static const char *n() { return "scs"; } };
template<> struct TN< C > { static const char *n() { return "sfs"; } };
template<> struct TN< D > { static const char *n() { return "ccs"; } };
template<> struct TN< E > { static const char *n() { return "cfs"; } };

#define FOR_SEQ(M) M(A) M(B) M(C)
#define SEQ A, B, C

#ifdef BRICKS_HAVE_TBB
#define FOR_PAR(M) M(D) M(E) M(F) M(G)
#define PAR D, E, F, G

template< typename T > using cus = tbb::concurrent_unordered_set< T >;
template< typename T > using chm = tbb::concurrent_hash_map< T, empty >;

using F = wrap_set< cus >;
using G = wrap_map< chm >;

template<> struct TN< F > { static const char *n() { return "cus"; } };
template<> struct TN< G > { static const char *n() { return "chm"; } };

#else
#define FOR_PAR(M) M(D) M(E)
#define PAR D, E
#endif

#define TvT(N) \
    template struct Bench< ThreadsVsTypes< N, 50, 4, PAR > >;

TvT(1024)
TvT(16 * 1024)

#define IvTh_PAR(T) \
  template struct Bench< ItemsVsThreads< 4, 0, T > >;

template struct Bench< ItemsVsTypes< 1, 0, SEQ, PAR > >;
template struct Bench< ItemsVsTypes< 2, 0, PAR > >;
template struct Bench< ItemsVsTypes< 4, 0, PAR > >;

#define IvR_SEQ(T) \
  template struct Bench< ItemsVsReserve< 1, T > >;
#define IvR_PAR(T) \
  template struct Bench< ItemsVsReserve< 1, T > >; \
  template struct Bench< ItemsVsReserve< 2, T > >; \
  template struct Bench< ItemsVsReserve< 4, T > >;

FOR_PAR(IvTh_PAR)

FOR_SEQ(IvR_SEQ)
FOR_PAR(IvR_PAR)

#undef FOR_SEQ
#undef FOR_PAR
#undef SEQ
#undef PAR
#undef IvT_PAR
#undef IvR_SEQ
#undef IvR_PAR


}
}

#endif // benchmarks

// vim: syntax=cpp tabstop=4 shiftwidth=4 expandtab ft=cpp
